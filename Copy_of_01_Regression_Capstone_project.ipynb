{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nowknowing/text-classification/blob/main/Copy_of_01_Regression_Capstone_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://weclouddata.s3.amazonaws.com/images/logos/wcd_logo_new_2.png\"  width='25%'>  \n",
        "\n",
        "Developed by WeCloudData\n",
        "<br></br>"
      ],
      "metadata": {
        "id": "loYI7gzuLPuS"
      },
      "id": "loYI7gzuLPuS"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d__XvlHsKubb"
      },
      "source": [
        "# Capstone Project: Your First Regression Model\n",
        "\n",
        "Welcome to your first capstone project in machine learning! In this notebook, you will build a complete regression pipeline using Python and the Kaggle House Prices dataset. You will learn how to:\n",
        "\n",
        "- Load and explore the dataset\n",
        "- Clean and preprocess the data\n",
        "- Engineer new features\n",
        "- Split the data into training and testing sets\n",
        "- Train various regression models\n",
        "- Evaluate model performance\n",
        "\n",
        "After following along with the House Prices example, you'll be asked to apply these steps on a dataset of your choice from Kaggle.\n",
        "\n",
        "Let's get started!"
      ],
      "id": "d__XvlHsKubb"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xn83ME8uKubi"
      },
      "source": [
        "## Step 1: Choosing a Dataset\n",
        "\n",
        "For this project, we are using the **House Prices: Advanced Regression Techniques** dataset from Kaggle. Download the dataset from the following link:\n",
        "\n",
        "[Kaggle House Prices Competition](https://www.kaggle.com/c/house-prices-advanced-regression-techniques)\n",
        "\n",
        "Make sure to download the `train.csv` file and place it in the same folder as this notebook.\n",
        "\n",
        "Once you are comfortable with these steps, try choosing another Kaggle regression dataset and follow the same process."
      ],
      "id": "Xn83ME8uKubi"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TTrnuswOKubj"
      },
      "source": [
        "### Other Kaggle Regression Dataset Suggestions\n",
        "\n",
        "Here are some other interesting Kaggle regression datasets that you can implement using similar steps:\n",
        "\n",
        "- **Bike Sharing Demand:** Predict the count of bike rentals.\n",
        "  - [Kaggle Bike Sharing Demand](https://www.kaggle.com/c/bike-sharing-demand)\n",
        "\n",
        "- **Wine Quality:** Predict the quality of red or white wines.\n",
        "  - [Kaggle Wine Quality Dataset](https://www.kaggle.com/uciml/red-wine-quality-cortez-et-al-2009)\n",
        "\n",
        "- **Medical Cost Personal Datasets:** Predict individual medical costs billed by health insurance.\n",
        "  - [Kaggle Medical Cost Personal Datasets](https://www.kaggle.com/mirichoi0218/insurance)\n",
        "\n",
        "Feel free to use one of these datasets for your own project once you have completed the House Prices example."
      ],
      "id": "TTrnuswOKubj"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gdp6xMxAKubj"
      },
      "outputs": [],
      "source": [
        "# Example: Loading the House Prices dataset\n",
        "import pandas as pd\n",
        "\n",
        "# Load the House Prices dataset (ensure train.csv is in your working directory)\n",
        "df = pd.read_csv('train.csv')\n",
        "\n",
        "print('Example Dataset: House Prices')\n",
        "display(df.head())"
      ],
      "id": "gdp6xMxAKubj"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xX7vZUYbKubl"
      },
      "source": [
        "### Exercise\n",
        "\n",
        "1. **Download a dataset from Kaggle** of your choice (for example, one of the suggestions above).\n",
        "2. Replace the example code above with code to load your chosen dataset into a Pandas DataFrame.\n",
        "3. Ensure your dataset has a target column for regression (for House Prices, the target is `SalePrice`)."
      ],
      "id": "xX7vZUYbKubl"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQciKPWeKubm"
      },
      "source": [
        "## Step 2: Loading and Exploring the Data\n",
        "\n",
        "In this step, we will explore the House Prices dataset by:\n",
        "\n",
        "- Viewing the first few rows\n",
        "- Getting summary statistics using `.describe()`\n",
        "- Checking the data structure with `.info()`\n",
        "- Looking for missing values\n",
        "\n",
        "This will help you understand the dataset before diving into cleaning and modeling."
      ],
      "id": "nQciKPWeKubm"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fjpvVscYKubn"
      },
      "outputs": [],
      "source": [
        "# View the first few rows\n",
        "print('First 5 rows of the House Prices dataset:')\n",
        "display(df.head())\n",
        "\n",
        "# Summary statistics\n",
        "print('Summary statistics:')\n",
        "display(df.describe())\n",
        "\n",
        "# Data structure and missing values\n",
        "print('Dataset info:')\n",
        "display(df.info())\n",
        "\n",
        "print('Missing values in each column:')\n",
        "display(df.isnull().sum())"
      ],
      "id": "fjpvVscYKubn"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hdn2zZZaKubp"
      },
      "source": [
        "### Exercise\n",
        "\n",
        "Using your own regression dataset from Kaggle, perform the same exploratory steps:\n",
        "\n",
        "- Print the first few rows\n",
        "- Display summary statistics and dataset info\n",
        "- Check for missing values"
      ],
      "id": "Hdn2zZZaKubp"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UfSp_QSEKubq"
      },
      "source": [
        "## Step 3: Data Cleaning and Preprocessing\n",
        "\n",
        "Real-world data is often messy. In this step, you'll learn to clean the House Prices dataset by:\n",
        "\n",
        "- Handling missing values\n",
        "- Converting categorical variables into numerical format\n",
        "- Scaling numerical features (if needed)\n",
        "\n",
        "Let's implement these preprocessing steps. In this example, we will fill missing numeric values with the median and categorical values with the mode, and then convert categorical variables to dummy variables."
      ],
      "id": "UfSp_QSEKubq"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YsZaTRT3Kubr"
      },
      "outputs": [],
      "source": [
        "# Create a copy of the DataFrame for cleaning\n",
        "df_clean = df.copy()\n",
        "\n",
        "# Fill missing numeric columns with the median\n",
        "numeric_cols = df_clean.select_dtypes(include=[\"float64\", \"int64\"]).columns\n",
        "for col in numeric_cols:\n",
        "    df_clean[col].fillna(df_clean[col].median(), inplace=True)\n",
        "\n",
        "# Fill missing categorical columns with the mode\n",
        "categorical_cols = df_clean.select_dtypes(include=[\"object\"]).columns\n",
        "for col in categorical_cols:\n",
        "    df_clean[col].fillna(df_clean[col].mode()[0], inplace=True)\n",
        "\n",
        "# Convert categorical variables into dummy/indicator variables\n",
        "df_clean = pd.get_dummies(df_clean, drop_first=True)\n",
        "\n",
        "print('Cleaned House Prices dataset:')\n",
        "display(df_clean.head())\n",
        "\n",
        "# Verify that there are no missing values\n",
        "print('Missing values after cleaning:')\n",
        "display(df_clean.isnull().sum())"
      ],
      "id": "YsZaTRT3Kubr"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Aday1bqKubs"
      },
      "source": [
        "### Exercise\n",
        "\n",
        "Apply similar cleaning and preprocessing steps to your own regression dataset:\n",
        "\n",
        "1. Handle any missing values (either fill or drop them).\n",
        "2. Convert categorical variables to numeric (using encoding methods such as get_dummies).\n",
        "3. Scale numerical features if necessary."
      ],
      "id": "_Aday1bqKubs"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AXtA856qKubs"
      },
      "source": [
        "## Step 4: Feature Engineering\n",
        "\n",
        "Feature engineering is the process of creating new features that might help improve your model's performance. For the House Prices dataset, a common new feature is **TotalSF** (total square footage), which can be calculated as:\n",
        "\n",
        "```\n",
        "TotalSF = TotalBsmtSF + 1stFlrSF + 2ndFlrSF\n",
        "```\n",
        "\n",
        "Let's create this new feature and visualize its distribution."
      ],
      "id": "AXtA856qKubs"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uDeppwSTKubs"
      },
      "outputs": [],
      "source": [
        "# Create a new feature 'TotalSF'\n",
        "df_clean['TotalSF'] = df_clean['TotalBsmtSF'] + df_clean['1stFlrSF'] + df_clean['2ndFlrSF']\n",
        "\n",
        "print('Dataset with new feature (TotalSF):')\n",
        "display(df_clean[['TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'TotalSF']].head())\n",
        "\n",
        "# Plot the distribution of TotalSF\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.histplot(df_clean['TotalSF'], kde=True)\n",
        "plt.title('Distribution of TotalSF')\n",
        "plt.xlabel('Total Square Footage')\n",
        "plt.show()"
      ],
      "id": "uDeppwSTKubs"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGYmRBMiKubt"
      },
      "source": [
        "### Exercise\n",
        "\n",
        "For your dataset, try to create at least one new feature. For example, consider combining existing features or computing a ratio/difference that might be useful for predicting the target variable.\n",
        "\n",
        "Add your new feature(s) to your DataFrame and visualize its/their distribution."
      ],
      "id": "PGYmRBMiKubt"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axKzjKnGKubt"
      },
      "source": [
        "## Step 5: Splitting the Data\n",
        "\n",
        "Before training your models, split your dataset into a training set and a testing set. The training set is used to build your model, while the testing set evaluates its performance on unseen data.\n",
        "\n",
        "For the House Prices dataset, our target variable is `SalePrice`."
      ],
      "id": "axKzjKnGKubt"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZiSz-tmUKubt"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Define features (X) and target (y). For House Prices, target is 'SalePrice'\n",
        "X = df_clean.drop(['SalePrice'], axis=1)\n",
        "y = df_clean['SalePrice']\n",
        "\n",
        "# Split the data into 80% training and 20% testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print('Training set shape:', X_train.shape)\n",
        "print('Testing set shape:', X_test.shape)"
      ],
      "id": "ZiSz-tmUKubt"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bGQZJBHWKubt"
      },
      "source": [
        "### Exercise\n",
        "\n",
        "Using your own regression dataset, perform the train-test split:\n",
        "\n",
        "- Define your features (X) and target (y).\n",
        "- Split the data into training and testing sets (80/20 or as appropriate)."
      ],
      "id": "bGQZJBHWKubt"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwy1TC3AKubu"
      },
      "source": [
        "## Step 6: Training Different Regression Models\n",
        "\n",
        "Now it's time to build some models! In this step, we'll train several regression algorithms using the House Prices training data. We'll work with the following models:\n",
        "\n",
        "- **Linear Regression**\n",
        "- **Decision Tree Regressor**\n",
        "- **Random Forest Regressor**\n",
        "- **k-Nearest Neighbors Regressor (KNN)**\n",
        "- **Support Vector Regressor (SVR)**\n",
        "\n",
        "Let's train these models using our preprocessed House Prices dataset."
      ],
      "id": "xwy1TC3AKubu"
    },
    {
      "cell_type": "markdown",
      "id": "cd987b61",
      "metadata": {
        "id": "cd987b61"
      },
      "source": [
        "## Step 6.5: Setting Hyperparameters\n",
        "\n",
        "Before training the regression models, it's important to configure their hyperparameters. Adjusting these values can significantly affect your model's performance. Here are some example settings:\n",
        "\n",
        "- **Decision Tree Regressor:**  \n",
        "  - *max_depth:* Limits the maximum depth of the tree (e.g., `max_depth=5`).  \n",
        "  - *min_samples_split:* Minimum number of samples required to split an internal node (e.g., `min_samples_split=10`).\n",
        "\n",
        "- **Random Forest Regressor:**  \n",
        "  - *n_estimators:* The number of trees in the forest (e.g., `n_estimators=100`).  \n",
        "  - *max_depth:* Maximum depth of each tree (e.g., `max_depth=7`).  \n",
        "  - *random_state:* A seed value for reproducibility (e.g., `random_state=42`).\n",
        "\n",
        "- **K-Nearest Neighbors Regressor:**  \n",
        "  - *n_neighbors:* The number of neighbors to consider (e.g., `n_neighbors=5`).\n",
        "\n",
        "- **Support Vector Regressor (SVR):**  \n",
        "  - *kernel:* The type of kernel to use (e.g., `'rbf'`).  \n",
        "  - *C:* Regularization parameter controlling the trade-off between fitting the training data and smoothness of the model (e.g., `C=1.0`).  \n",
        "  - *epsilon:* Specifies the epsilon-tube within which no penalty is associated in the training loss function (e.g., `epsilon=0.1`).\n",
        "\n",
        "Feel free to experiment with these hyperparameters to see how they impact the performance of your regression models.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ge9txPCjKubx"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.svm import SVR\n",
        "\n",
        "# Set hyperparameters for each model\n",
        "lr_model = LinearRegression()\n",
        "\n",
        "dt_model = DecisionTreeRegressor(max_depth=5, min_samples_split=10)\n",
        "rf_model = RandomForestRegressor(n_estimators=100, max_depth=7, random_state=42)\n",
        "knn_model = KNeighborsRegressor(n_neighbors=5)\n",
        "svr_model = SVR(kernel='rbf', C=1.0, epsilon=0.1)\n",
        "\n",
        "# Initialize the models with the hyperparameters\n",
        "models = {\n",
        "    'Linear Regression': lr_model,\n",
        "    'Decision Tree': dt_model,\n",
        "    'Random Forest': rf_model,\n",
        "    'K-Nearest Neighbors': knn_model,\n",
        "    'SVR': svr_model\n",
        "}\n",
        "\n",
        "# Train each model and store predictions\n",
        "predictions = {}\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "    pred = model.predict(X_test)\n",
        "    predictions[name] = pred\n",
        "    print(f\"{name} model trained.\")\n",
        "\n",
        "print('\\nAll models have been trained on the House Prices dataset!')\n"
      ],
      "id": "Ge9txPCjKubx"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aeOmTwm9Kubx"
      },
      "source": [
        "### Exercise\n",
        "\n",
        "Repeat this step using your own regression dataset:\n",
        "\n",
        "1. Initialize similar regression models.\n",
        "2. Train each model on the training set of your dataset.\n",
        "3. Save the predictions for later evaluation."
      ],
      "id": "aeOmTwm9Kubx"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Z0Yf9MZKucM"
      },
      "source": [
        "## Step 7: Evaluating Model Performance\n",
        "\n",
        "After training your models, evaluate how well they perform on the testing data. For regression tasks, common metrics include:\n",
        "\n",
        "- **Mean Squared Error (MSE)**\n",
        "- **Mean Absolute Error (MAE)**\n",
        "- **R² Score**\n",
        "\n",
        "Let's compute these metrics for the models trained on the House Prices dataset."
      ],
      "id": "_Z0Yf9MZKucM"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-DyMl3zMKucM"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "for name, pred in predictions.items():\n",
        "    mse = mean_squared_error(y_test, pred)\n",
        "    mae = mean_absolute_error(y_test, pred)\n",
        "    r2 = r2_score(y_test, pred)\n",
        "    print(f\"\\nModel: {name}\")\n",
        "    print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
        "    print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
        "    print(f\"R² Score: {r2:.2f}\")\n",
        "    print('---------------------------')"
      ],
      "id": "-DyMl3zMKucM"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G30QfYclKucN"
      },
      "source": [
        "### Exercise\n",
        "\n",
        "For your dataset, evaluate your trained regression models using similar metrics:\n",
        "\n",
        "1. Calculate and review metrics such as MSE, MAE, and R² Score for each model.\n",
        "2. Compare the performance of the different models."
      ],
      "id": "G30QfYclKucN"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZALPnGryKucO"
      },
      "source": [
        "## Final Thoughts and Next Steps\n",
        "\n",
        "Great job! You have now built a complete regression pipeline using the House Prices dataset:\n",
        "\n",
        "1. **Choosing a Dataset:** Downloaded the House Prices dataset from Kaggle.\n",
        "2. **Loading and Exploring the Data:** Loaded and explored the dataset.\n",
        "3. **Data Cleaning and Preprocessing:** Cleaned and prepared the data.\n",
        "4. **Feature Engineering:** Created new features (e.g., TotalSF).\n",
        "5. **Splitting the Data:** Divided the data into training and testing sets.\n",
        "6. **Training Models:** Built several regression models.\n",
        "7. **Evaluating Performance:** Evaluated the models on unseen data.\n",
        "\n",
        "### Next Steps\n",
        "\n",
        "- Experiment with other Kaggle regression datasets and try replicating these steps.\n",
        "- Explore additional preprocessing techniques and feature engineering ideas.\n",
        "- Once comfortable, try incorporating more advanced techniques such as hyperparameter tuning.\n",
        "\n",
        "Keep experimenting and enjoy your journey into machine learning!"
      ],
      "id": "ZALPnGryKucO"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjmMyfdxKucO"
      },
      "source": [
        "## References and Further Reading\n",
        "\n",
        "Here are some useful resources for the modules and functions used in this notebook:\n",
        "\n",
        "- **Pandas:** [Pandas Documentation](https://pandas.pydata.org/pandas-docs/stable/)\n",
        "- **NumPy:** [NumPy Documentation](https://numpy.org/doc/stable/)\n",
        "- **Matplotlib:** [Matplotlib API Reference](https://matplotlib.org/stable/api/index.html)\n",
        "- **Seaborn:** [Seaborn API Reference](https://seaborn.pydata.org/api.html)\n",
        "- **Scikit-Learn:** [Scikit-Learn Documentation](https://scikit-learn.org/stable/documentation.html)\n",
        "  - [train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)\n",
        "  - [LinearRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html)\n",
        "  - [DecisionTreeRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html)\n",
        "  - [RandomForestRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html)\n",
        "  - [KNeighborsRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html)\n",
        "  - [SVR](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html)\n",
        "  - [mean_squared_error](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html)\n",
        "  - [mean_absolute_error](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_absolute_error.html)\n",
        "  - [r2_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html)\n",
        "\n",
        "These resources will help you learn more about the functions and libraries used throughout the notebook."
      ],
      "id": "rjmMyfdxKucO"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}